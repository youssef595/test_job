{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def prepare_command(command: dict) -> str:\n",
    "    \"\"\"Converts dictionary command to the string formatted commands.\"\"\"\n",
    "    return f\"'{json.dumps(command)}'\"\n",
    "\n",
    "import ads\n",
    "\n",
    "ads.set_auth(\"resource_principal\")  # Supported values: resource_principal, api_key\n",
    "import ocifs\n",
    "\n",
    "fs = ocifs.OCIFileSystem()\n",
    "\n",
    "\n",
    "directory_path = \"sa-cat-data-neu@frsulmjrrb5y/raw_csv/\"\n",
    "\n",
    "file_list = fs.ls(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dataflow.magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "compartment_id = os.environ.get(\"NB_SESSION_COMPARTMENT_OCID\")\n",
    "logs_bucket_uri = \"oci://spark_log@frsulmjrrb5y/logs\"\n",
    "metastore_id = \"<metastore_id>\"\n",
    "compartment_id\n",
    "\n",
    "command = prepare_command(\n",
    "    {\n",
    "        \"compartmentId\": compartment_id,\n",
    "        \"displayName\": \"TestDataFLowSessionFlexShapes\",\n",
    "        \"language\": \"PYTHON\",\n",
    "        \"sparkVersion\": \"3.2.1\",\n",
    "        \"numExecutors\": 1,\n",
    "        \"driverShape\": \"VM.Standard.E4.Flex\",\n",
    "        \"executorShape\": \"VM.Standard.E4.Flex\",\n",
    "        \"driverShapeConfig\": {\"ocpus\": 2, \"memoryInGBs\": 32},\n",
    "        \"executorShapeConfig\": {\"ocpus\": 2, \"memoryInGBs\": 32},\n",
    "        \"type\": \"SESSION\",\n",
    "        \"logsBucketUri\": logs_bucket_uri,\n",
    "        \"configuration\": {\n",
    "            \"fs.oci.client.hostname\": \"https://frsulmjrrb5y.compat.objectstorage.eu-frankfurt-1.oraclecloud.com\"\n",
    "        },\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%create_session -l python -c $command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "bucket_name = \"sa-cat-data-neu\"\n",
    "namespace = \"frsulmjrrb5y\"\n",
    "folder_name = \"working\"\n",
    "folder = \"curated\"\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "dico_data2=dict()\n",
    "for i in ['attestations_ref','avenants_ref','clients_ref','clt_att_ref','contrats_ref','garanties_ref'\n",
    "          ,'infosmandataires_ref','persimpliq_ref']:\n",
    "    dico_data2[i] = spark.read.parquet(f\"oci://{bucket_name}@{namespace}/{folder_name}/{folder}/{i}.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "dico_data['clients_ref'].write.mode('overwrite').parquet(f\"oci://{bucket_name}@{namespace}/working/curated/client_ref_test.parquet\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
